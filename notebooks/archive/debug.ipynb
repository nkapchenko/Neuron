{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from neuron.mnist import mnist_loader\n",
    "import neuron.network as network\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from recordtype  import recordtype\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron.activation_functions import sigmoid, sigmoid_prime\n",
    "from neuron.choice import J, J_derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [784, 30, 10]\n",
    "n = 1\n",
    "nepochs = 1\n",
    "learning_rate = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_attr = 'nb_layers sizes biases weights activation_function activation_function_derivative'\n",
    "debug = recordtype ('debug', debug_attr)\n",
    "self = debug(*(None for _ in range(len(debug_attr.split()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "self.nb_layers = len(sizes)\n",
    "self.sizes = sizes # ex. (748, 30 , 10)\n",
    "self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "self.weights = [np.random.randn(y, x)\n",
    "                for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "\n",
    "self.activation_function = sigmoid\n",
    "self.activation_function_derivative = sigmoid_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y), (validation_X, validation_y), (test_X, test_y) =  mnist_loader.perf_load_data_wrapper()\n",
    "X = X[0:n]\n",
    "y = y[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X = array([[0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.01172, 0.07031,\n",
    "        0.07031, 0.07031, 0.49219, 0.53125, 0.68359, 0.10156, 0.64844,\n",
    "        0.99609, 0.96484, 0.49609, 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.11719, 0.14062, 0.36719, 0.60156, 0.66406, 0.98828,\n",
    "        0.98828, 0.98828, 0.98828, 0.98828, 0.87891, 0.67188, 0.98828,\n",
    "        0.94531, 0.76172, 0.25   , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.19141, 0.92969, 0.98828, 0.98828, 0.98828, 0.98828, 0.98828,\n",
    "        0.98828, 0.98828, 0.98828, 0.98047, 0.36328, 0.32031, 0.32031,\n",
    "        0.21875, 0.15234, 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.07031, 0.85547, 0.98828, 0.98828, 0.98828, 0.98828, 0.98828,\n",
    "        0.77344, 0.71094, 0.96484, 0.94141, 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.3125 , 0.60938, 0.41797, 0.98828, 0.98828, 0.80078,\n",
    "        0.04297, 0.     , 0.16797, 0.60156, 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.05469, 0.00391, 0.60156, 0.98828, 0.35156,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.54297, 0.98828, 0.74219,\n",
    "        0.00781, 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.04297, 0.74219, 0.98828,\n",
    "        0.27344, 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.13672, 0.94141,\n",
    "        0.87891, 0.625  , 0.42188, 0.00391, 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.31641,\n",
    "        0.9375 , 0.98828, 0.98828, 0.46484, 0.09766, 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.17578, 0.72656, 0.98828, 0.98828, 0.58594, 0.10547, 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.0625 , 0.36328, 0.98438, 0.98828, 0.73047, 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.97266, 0.98828, 0.97266, 0.25   ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.17969, 0.50781, 0.71484, 0.98828, 0.98828, 0.80859, 0.00781,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.15234, 0.57812,\n",
    "        0.89453, 0.98828, 0.98828, 0.98828, 0.97656, 0.71094, 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.09375, 0.44531, 0.86328, 0.98828,\n",
    "        0.98828, 0.98828, 0.98828, 0.78516, 0.30469, 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.08984, 0.25781, 0.83203, 0.98828, 0.98828, 0.98828,\n",
    "        0.98828, 0.77344, 0.31641, 0.00781, 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.07031,\n",
    "        0.66797, 0.85547, 0.98828, 0.98828, 0.98828, 0.98828, 0.76172,\n",
    "        0.3125 , 0.03516, 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.21484, 0.67188, 0.88281,\n",
    "        0.98828, 0.98828, 0.98828, 0.98828, 0.95312, 0.51953, 0.04297,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.53125, 0.98828, 0.98828,\n",
    "        0.98828, 0.82812, 0.52734, 0.51562, 0.0625 , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
    "        0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ]],\n",
    "      dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "miny = array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = X.shape[0]//1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD(X, y, epochs, batch_size=1, learning_rate=1, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(batch_size, int), 'batch_size should be int'\n",
    "        \n",
    "n = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = list(zip(X, y))\n",
    "np.random.shuffle(Xy)\n",
    "batches = np.array([Xy[k:k + batch_size] for k in range(0, n, batch_size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbatch, ybatch= [np.asarray(x) for x in zip(*batch)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDATE_BATCH ( X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xbatch\n",
    "y = ybatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert  X.shape[1] == self.sizes[0]\n",
    "assert  y.shape[1] == self.sizes[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropa(X, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X\n",
    "answers = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = X.T\n",
    "answers = answers.T\n",
    "activations = [activation]\n",
    "zs = []\n",
    "\n",
    "# Forward\n",
    "for w, b in zip(self.weights, self.biases): \n",
    "    z = w.dot(activation) + b\n",
    "    zs.append(z)\n",
    "    activation = self.activation_function(z)\n",
    "    activations.append(activation)\n",
    "    \n",
    "# Backpropa\n",
    "network_answers = activations[-1] # (K, B) and answers (K, B)\n",
    "delta = J_derivative(network_answers, answers) * self.activation_function_derivative(zs[-1])\n",
    "nik_delta = delta\n",
    "deltas = [delta]\n",
    "for L in range (2, self.nb_layers):\n",
    "    delta = self.weights[-L+1].T.dot(delta) * self.activation_function_derivative(zs[-L])\n",
    "    deltas = [delta] + deltas\n",
    "\n",
    "# Gradients\n",
    "\n",
    "dJdb = [delta.sum(axis=1).reshape(len(delta),1) for delta in deltas]\n",
    "dJdw = [delta.dot(a.T) for delta, a in zip(deltas, activations[:-1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end backpropa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.weights = [w - learning_rate * djdw for w, djdw in zip(self.weights, dJdw)]\n",
    "self.biases =  [b - learning_rate * djdb for b, djdb in zip(self.biases,  dJdb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end Update_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = -1\n",
    "out_neuron = 4\n",
    "hidden_neuron = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7294742781563903"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.weights[layer][out_neuron][hidden_neuron]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04181749474035426"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate * dJdw[layer][out_neuron][hidden_neuron]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00376],\n",
       "       [ 0.1006 ],\n",
       "       [ 0.12249],\n",
       "       [ 0.05008],\n",
       "       [ 0.0784 ],\n",
       "       [-0.13335],\n",
       "       [ 0.0007 ],\n",
       "       [ 0.01967],\n",
       "       [ 0.10221],\n",
       "       [ 0.00276]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJdb[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progonka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = Xbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert input_matrix.shape[1] == 784, 'X should be (n, 784)'\n",
    "activation = input_matrix.T # (m, n)\n",
    "for b, w in zip(self.biases, self.weights):\n",
    "    z = w.dot(activation) + b  # (k_[i], n)\n",
    "    activation = self.activation_function(z)  # (k_[i], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.59992e-02],\n",
       "       [3.92086e-04],\n",
       "       [7.08844e-03],\n",
       "       [5.68539e-01],\n",
       "       [1.21485e-01],\n",
       "       [9.99858e-01],\n",
       "       [9.73401e-03],\n",
       "       [2.68973e-01],\n",
       "       [2.11515e-03],\n",
       "       [9.97576e-01]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
